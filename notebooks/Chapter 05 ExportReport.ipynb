{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FZpS8XHCOVM-"
      },
      "outputs": [],
      "source": [
        "# One-time setup (only if you didn't run Chapter 2)\n",
        "%pip -q install ezc3d pandas\n",
        "!wget -q https://raw.githubusercontent.com/hmok/BiomechPythonAI_Guide/main/notebooks/Chapter1Input.py -O Chapter1Input.py\n",
        "!wget -q https://raw.githubusercontent.com/hmok/BiomechPythonAI_Guide/main/notebooks/Chapter2Input.py -O Chapter2Input.py\n",
        "%run Chapter1Input.py\n",
        "%run Chapter2Input.py\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A8LNwGNYOc_n"
      },
      "outputs": [],
      "source": [
        "# Step 0. Helpers that match Chapter 4’s data handling\n",
        "# Same packages used before\n",
        "import os, io, base64, json, math\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "P = c3d[\"parameters\"]\n",
        "\n",
        "def pval(g,k, default=None):\n",
        "    try:\n",
        "        return P[g][k][\"value\"]\n",
        "    except Exception:\n",
        "        return default\n",
        "\n",
        "def get_rates():\n",
        "    pt_rate = float(pval(\"POINT\",\"RATE\",[np.nan])[0]) if pval(\"POINT\",\"RATE\",None) is not None else np.nan\n",
        "    an_rate = float(pval(\"ANALOG\",\"RATE\",[np.nan])[0]) if pval(\"ANALOG\",\"RATE\",None) is not None else np.nan\n",
        "    return pt_rate, an_rate\n",
        "\n",
        "def reshape_analogs():\n",
        "    raw = c3d[\"data\"].get(\"analogs\", None)\n",
        "    if raw is None:\n",
        "        return np.zeros((0,0))\n",
        "    A = np.array(raw)\n",
        "    if A.ndim == 2:\n",
        "        return A\n",
        "    if A.ndim == 3:\n",
        "        # mirror Chapter 4 shape logic\n",
        "        if A.shape[0] < 16 and A.shape[1] > A.shape[0]:\n",
        "            return np.moveaxis(A, 0, -1).reshape(A.shape[1], -1)\n",
        "        return A.reshape(A.shape[0], -1)\n",
        "    return A.reshape(A.shape[0], -1)\n",
        "\n",
        "def get_labels():\n",
        "    point_labels = pval(\"POINT\",\"LABELS\", []) or []\n",
        "    analog_labels = pval(\"ANALOG\",\"LABELS\", []) or []\n",
        "    analog_units  = pval(\"ANALOG\",\"UNITS\",  []) or []\n",
        "    return [str(x) for x in point_labels], [str(x) for x in analog_labels], [str(x) for x in analog_units]\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "imntGMaiOlLk"
      },
      "outputs": [],
      "source": [
        "# Step 1. Find a usable vertical force, just like the Chapter 4 picker\n",
        "def soft_detrend(y):\n",
        "    return y - np.nanmedian(y)\n",
        "\n",
        "def ensure_positive_down(y):\n",
        "    # choose the sign with larger positive peaks\n",
        "    pos_peak = np.nanpercentile(np.maximum(y, 0), 99)\n",
        "    neg_peak = np.nanpercentile(np.maximum(-y, 0), 99)\n",
        "    return y if pos_peak >= neg_peak else -y\n",
        "\n",
        "def pick_fz_or_mag(an, labels):\n",
        "    # prefer any Fz-like label, else build a magnitude from Fx,Fy,Fz\n",
        "    fz_idx = [i for i,s in enumerate(labels) if \"fz\" in s.lower() or \"vf\" in s.lower()]\n",
        "    for i in fz_idx:\n",
        "        y = an[i].astype(float)\n",
        "        y = ensure_positive_down(soft_detrend(y))\n",
        "        if np.nanmax(np.abs(y)) > 1e-6:\n",
        "            return y, \"Fz\", i\n",
        "    fx = next((i for i,s in enumerate(labels) if \"fx\" in s.lower()), None)\n",
        "    fy = next((i for i,s in enumerate(labels) if \"fy\" in s.lower()), None)\n",
        "    fz = next((i for i,s in enumerate(labels) if \"fz\" in s.lower()), None)\n",
        "    if fx is not None and fy is not None and fz is not None:\n",
        "        mag = np.sqrt(an[fx]**2 + an[fy]**2 + an[fz]**2).astype(float)\n",
        "        return soft_detrend(mag), \"GRF magnitude\", (fx,fy,fz)\n",
        "    return None, None, None\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P1x1KJc4OnxY"
      },
      "outputs": [],
      "source": [
        "# Step 2. Detect stance windows and resample cycles to 0..100 percent\n",
        "def clean_contact_bool(x, min_len_samples):\n",
        "    x = x.astype(bool)\n",
        "    on  = np.where(np.diff(x.astype(int)) == 1)[0] + 1\n",
        "    off = np.where(np.diff(x.astype(int)) == -1)[0] + 1\n",
        "    if x[0]:  on  = np.r_[0, on]\n",
        "    if x[-1]: off = np.r_[off, len(x)]\n",
        "    y = x.copy()\n",
        "    for s,e in zip(on,off):\n",
        "        if e - s < min_len_samples:\n",
        "            y[s:e] = False\n",
        "    return y\n",
        "\n",
        "def detect_stance_pairs(sig, an_rate, thr_frac=0.05, thr_abs_N=20.0, min_stance_s=0.15):\n",
        "    peak_est = np.nanpercentile(np.abs(sig), 98)\n",
        "    thr = max(thr_frac * peak_est, thr_abs_N)\n",
        "    contact = sig > thr\n",
        "    contact = clean_contact_bool(contact, int(min_stance_s * an_rate))\n",
        "    starts = np.where(np.diff(contact.astype(int)) == 1)[0] + 1\n",
        "    ends   = np.where(np.diff(contact.astype(int)) == -1)[0] + 1\n",
        "    if contact[0] and (len(ends) == len(starts) + 1): starts = np.r_[0, starts]\n",
        "    if contact[-1] and (len(starts) == len(ends) + 1): ends = np.r_[ends, len(contact)]\n",
        "    return [(s,e) for s,e in zip(starts,ends) if e > s]\n",
        "\n",
        "def resample_cycle(y, s, e, n=101):\n",
        "    if e - s < 3:\n",
        "        return np.full(n, np.nan)\n",
        "    xs = np.linspace(s, e - 1, e - s)\n",
        "    xt = np.linspace(s, e - 1, n)\n",
        "    return np.interp(xt, xs, y[s:e])\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vi2WDxfqOqPP"
      },
      "outputs": [],
      "source": [
        "# Step 3. Compute beginner-friendly metrics that people actually use\n",
        "# Works whether you have N or 0 cycles. Add body mass if you want BW normalization.\n",
        "def per_cycle_metrics(sig, t, pairs, mass_kg=None):\n",
        "    rows = []\n",
        "    g = 9.81\n",
        "    for k,(s,e) in enumerate(pairs):\n",
        "        y = sig[s:e].astype(float)\n",
        "        tt = t[s:e].astype(float)\n",
        "        if len(y) < 3:\n",
        "            continue\n",
        "        peakN = float(np.nanmax(y))\n",
        "        pk_idx = int(np.nanargmax(y))\n",
        "        # crude loading rate: slope from initial rise to 90 percent of peak\n",
        "        target = 0.9 * peakN\n",
        "        rise_idx = np.argmax(y > max(1e-9, target))\n",
        "        rise_idx = max(rise_idx, 1)\n",
        "        lr = (y[rise_idx] - y[0]) / max(tt[rise_idx] - tt[0], 1e-6)\n",
        "        contact_time = float(tt[-1] - tt[0])\n",
        "        out = {\n",
        "            \"Cycle\": k+1,\n",
        "            \"PeakN\": peakN,\n",
        "            \"ContactTime_s\": contact_time,\n",
        "            \"LoadingRate_N_per_s\": lr,\n",
        "        }\n",
        "        if mass_kg and mass_kg > 0:\n",
        "            out[\"Peak_BW\"] = peakN / (mass_kg * g)\n",
        "            out[\"LoadingRate_BW_per_s\"] = lr / (mass_kg * g)\n",
        "        rows.append(out)\n",
        "    return pd.DataFrame(rows)\n",
        "\n",
        "def cadence_from_pairs(pairs, an_rate):\n",
        "    if len(pairs) < 2:\n",
        "        return np.nan\n",
        "    # step events as stance starts\n",
        "    starts = np.array([s for s,_ in pairs], dtype=float)\n",
        "    dur_s  = (starts[-1] - starts[0]) / an_rate\n",
        "    steps  = len(starts)\n",
        "    return 60.0 * steps / max(dur_s, 1e-6)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qCh4-IFROtG3"
      },
      "outputs": [],
      "source": [
        "# Step 4. Figures that match Chapter 4 style, plus overlays and bars\n",
        "def save_fig(path):\n",
        "    os.makedirs(os.path.dirname(path), exist_ok=True)\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(path, dpi=150, bbox_inches=\"tight\")\n",
        "    plt.show()\n",
        "\n",
        "def fig_time_with_events(t, sig, pairs, title, ylabel, out_path):\n",
        "    plt.figure(figsize=(8,3))\n",
        "    plt.plot(t, sig, label=\"Signal\")\n",
        "    for s,e in pairs:\n",
        "        plt.axvspan(t[s], t[e-1], alpha=0.2, label=\"Stance\" if s==pairs[0][0] else None)\n",
        "    plt.xlabel(\"Time [s]\"); plt.ylabel(ylabel); plt.title(title); plt.grid(True, alpha=0.3)\n",
        "    if pairs: plt.legend()\n",
        "    save_fig(out_path)\n",
        "\n",
        "def fig_cycles_overlay(sig, pairs, npts, title, ylabel, out_path):\n",
        "    if not pairs:\n",
        "        return None\n",
        "    X = np.linspace(0,100,npts)\n",
        "    C = np.array([resample_cycle(sig, s, e, npts) for s,e in pairs])\n",
        "    meanC = np.nanmean(C, axis=0)\n",
        "    plt.figure(figsize=(8,3))\n",
        "    for i in range(C.shape[0]): plt.plot(X, C[i], alpha=0.35)\n",
        "    plt.plot(X, meanC, linewidth=2, label=\"Mean\")\n",
        "    plt.xlabel(\"Gait cycle [%]\"); plt.ylabel(ylabel); plt.title(title); plt.grid(True, alpha=0.3); plt.legend()\n",
        "    save_fig(out_path)\n",
        "    return C, meanC\n",
        "\n",
        "def fig_bar_peaks(df, out_path):\n",
        "    if df is None or df.empty:\n",
        "        return\n",
        "    means = df[\"PeakN\"].mean() if \"PeakN\" in df else np.nan\n",
        "    plt.figure(figsize=(4,3))\n",
        "    plt.bar([\"All cycles\"], [means])\n",
        "    plt.ylabel(\"Peak [N]\")\n",
        "    plt.title(\"Peak GRF average\")\n",
        "    save_fig(out_path)\n",
        "\n",
        "def fig_scatter_peaks(df, out_path):\n",
        "    if df is None or df.empty:\n",
        "        return\n",
        "    plt.figure(figsize=(5,3))\n",
        "    plt.scatter(np.arange(len(df))+1, df[\"PeakN\"])\n",
        "    plt.xlabel(\"Cycle #\"); plt.ylabel(\"Peak [N]\"); plt.title(\"Per cycle peaks\")\n",
        "    plt.grid(True, alpha=0.3)\n",
        "    save_fig(out_path)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z3Fyy6kcOwPX"
      },
      "outputs": [],
      "source": [
        "# Step 5. Build a tiny report folder with CSV and HTML\n",
        "def img_to_base64(path):\n",
        "    with open(path, \"rb\") as f:\n",
        "        return \"data:image/png;base64,\" + base64.b64encode(f.read()).decode(\"ascii\")\n",
        "\n",
        "def write_report(folder, meta, df_metrics, images):\n",
        "    os.makedirs(folder, exist_ok=True)\n",
        "    csv_path = os.path.join(folder, \"metrics.csv\")\n",
        "    df_metrics.to_csv(csv_path, index=False)\n",
        "\n",
        "    html_path = os.path.join(folder, \"report.html\")\n",
        "    with open(html_path, \"w\") as f:\n",
        "        f.write(\"<h1>Biomechanics Report</h1>\")\n",
        "        f.write(\"<h3>Summary</h3>\")\n",
        "        f.write(\"<pre>\"+json.dumps(meta, indent=2)+\"</pre>\")\n",
        "        f.write(\"<h3>Metrics</h3>\")\n",
        "        f.write(df_metrics.to_html(index=False))\n",
        "        for title, p in images:\n",
        "            if p and os.path.exists(p):\n",
        "                f.write(f\"<h3>{title}</h3>\")\n",
        "                f.write(f'<img src=\"{img_to_base64(p)}\" style=\"max-width:900px;\">')\n",
        "    return {\"csv\": csv_path, \"html\": html_path}\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pJxe0p-rOz01"
      },
      "outputs": [],
      "source": [
        "# Step 6. One clean run\n",
        "# This block does everything: finds vertical force, detects stance, computes metrics, makes figures, writes the bundle.\n",
        "# Configs\n",
        "OUTPUT = \"report_outputs\"\n",
        "CYCLE_NPTS = 101\n",
        "MASS_KG = None  # set to a number if you want BW normalization, for example 75.0\n",
        "\n",
        "# Data\n",
        "pt_rate, an_rate = get_rates()\n",
        "an = reshape_analogs()\n",
        "point_labels, analog_labels, analog_units = get_labels()\n",
        "sig, sig_name, src = pick_fz_or_mag(an, analog_labels)\n",
        "\n",
        "if sig is None or an.shape[1] == 0 or np.isnan(an_rate):\n",
        "    print(\"Could not build a reporting signal. Check analog labels and ANALOG.RATE.\")\n",
        "else:\n",
        "    t_an = np.arange(an.shape[1]) / an_rate\n",
        "    pairs = detect_stance_pairs(sig, an_rate, thr_frac=0.05, thr_abs_N=20.0, min_stance_s=0.15)\n",
        "    print(f\"Detected {len(pairs)} stance phases using {sig_name}\")\n",
        "\n",
        "    # Metrics\n",
        "    df = per_cycle_metrics(sig, t_an, pairs, mass_kg=MASS_KG)\n",
        "    cad = cadence_from_pairs(pairs, an_rate)\n",
        "    meta = {\n",
        "        \"Signal\": sig_name,\n",
        "        \"AnalogRate_Hz\": float(an_rate),\n",
        "        \"Cycles\": int(len(pairs)),\n",
        "        \"Cadence_spm\": None if math.isnan(cad) else float(cad),\n",
        "        \"BW_norm\": bool(MASS_KG is not None),\n",
        "    }\n",
        "\n",
        "    # Figures\n",
        "    fig1 = os.path.join(OUTPUT, \"time_with_stance.png\")\n",
        "    fig_time_with_events(t_an, sig, pairs, f\"{sig_name} over time\", f\"{sig_name}\", fig1)\n",
        "\n",
        "    cyc = fig_cycles_overlay(sig, pairs, CYCLE_NPTS, f\"{sig_name} cycles\", f\"{sig_name}\", os.path.join(OUTPUT, \"cycles_overlay.png\"))\n",
        "    fig_bar_peaks(df, os.path.join(OUTPUT, \"peaks_bar.png\"))\n",
        "    fig_scatter_peaks(df, os.path.join(OUTPUT, \"peaks_scatter.png\"))\n",
        "\n",
        "    # Write bundle\n",
        "    imgs = [\n",
        "        (\"Time plot with stance\", fig1),\n",
        "        (\"Cycle overlay\", os.path.join(OUTPUT, \"cycles_overlay.png\")),\n",
        "        (\"Peak bar\", os.path.join(OUTPUT, \"peaks_bar.png\")),\n",
        "        (\"Peak scatter\", os.path.join(OUTPUT, \"peaks_scatter.png\")),\n",
        "    ]\n",
        "    out_paths = write_report(OUTPUT, meta, df, imgs)\n",
        "\n",
        "    print(\"Saved:\")\n",
        "    print(\" CSV:\", out_paths[\"csv\"])\n",
        "    print(\" HTML:\", out_paths[\"html\"])\n",
        "    if df.empty:\n",
        "        print(\"Note: no cycles with metrics. Adjust threshold or units if needed.\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z6XhtAZhO6mr"
      },
      "outputs": [],
      "source": [
        "# Optional. Left vs right symmetry, same guardrails as Chapter 4\n",
        "# If you have separate left and right force channels or separate plates, duplicate the stance detection on each and reuse the cycle overlay.\n",
        "# Sketch: if you had Fz1 and Fz2\n",
        "labels = [s.lower() for s in analog_labels]\n",
        "try:\n",
        "    fz1 = an[labels.index(next(s for s in labels if \"fz1\" in s))]\n",
        "    fz2 = an[labels.index(next(s for s in labels if \"fz2\" in s))]\n",
        "    fz1 = ensure_positive_down(soft_detrend(fz1))\n",
        "    fz2 = ensure_positive_down(soft_detrend(fz2))\n",
        "\n",
        "    pairs_L = detect_stance_pairs(fz1, an_rate)\n",
        "    pairs_R = detect_stance_pairs(fz2, an_rate)\n",
        "\n",
        "    # cycles\n",
        "    C_L = np.array([resample_cycle(fz1, s, e, CYCLE_NPTS) for s,e in pairs_L]) if pairs_L else np.empty((0, CYCLE_NPTS))\n",
        "    C_R = np.array([resample_cycle(fz2, s, e, CYCLE_NPTS) for s,e in pairs_R]) if pairs_R else np.empty((0, CYCLE_NPTS))\n",
        "\n",
        "    if C_L.size and C_R.size:\n",
        "        X = np.linspace(0,100,CYCLE_NPTS)\n",
        "        Lm = np.nanmean(C_L, axis=0); Rm = np.nanmean(C_R, axis=0)\n",
        "        plt.figure(figsize=(8,3))\n",
        "        plt.plot(X, Lm, label=\"Left\"); plt.plot(X, Rm, label=\"Right\")\n",
        "        plt.xlabel(\"Gait cycle [%]\"); plt.ylabel(\"Fz\"); plt.title(\"Symmetry overlay\"); plt.grid(True, alpha=0.3); plt.legend()\n",
        "        save_fig(os.path.join(OUTPUT, \"symmetry_overlay.png\"))\n",
        "        # simple symmetry index by area\n",
        "        aL = np.trapz(Lm, x=X); aR = np.trapz(Rm, x=X)\n",
        "        if (aL + aR) != 0:\n",
        "            sym_idx = 100.0 * (aL - aR) / ((aL + aR) / 2.0)\n",
        "            print(f\"Symmetry index [%]: {sym_idx:.2f}\")\n",
        "    else:\n",
        "        print(\"Symmetry skipped, missing L or R cycles.\")\n",
        "except StopIteration:\n",
        "    print(\"Did not find explicit FZ1 or FZ2 labels, symmetry skipped.\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9e238e99"
      },
      "source": [
        "# Chapter 5. Export / Report\n",
        "\n",
        "You already loaded data, parsed signals, detected events, and drew the core visuals. Now close the loop. Take the exact signals and cycles you just validated, compute a small set of metrics, save a few clean figures, and drop an HTML plus CSV bundle that anyone can open. The point is not fancy formatting. The point is a repeatable bundle you can reuse across trials and sessions.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0f198662"
      },
      "source": [
        "## What you will produce\n",
        "\n",
        "- Per-cycle metrics: peak vertical force, contact time, simple loading rate\n",
        "- Three figures that match Chapter 4 style: time plot with stance shading, cycle overlay, per-cycle peaks\n",
        "- An output folder `report_outputs` with `metrics.csv` and `report.html`\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c9c40741"
      },
      "source": [
        "---\n",
        "**Ebook:** *A Hands-On Guide to Biomechanics Data Analysis with Python and AI*  \n",
        "**Author:** Dr. Hossein Mokhtarzadeh  \n",
        "**Powered by:** PoseIQ™\n",
        "\n",
        "This notebook loads sample biomechanics data and shows how to bring it into Python.\n",
        "\n",
        "> Tip: in Colab or Jupyter, select **Runtime -> Run all**.\n",
        "---\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f399b6ca"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Chapter 5 setup: imports and output folder\n",
        "import os, math, base64, io, json, textwrap, itertools\n",
        "from pathlib import Path\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Do not specify styles or colors to keep things simple and portable\n",
        "OUTPUT_DIR = Path(\"report_outputs\")\n",
        "OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "print(f\"Outputs will be saved to: {OUTPUT_DIR.resolve()}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "61b1016d"
      },
      "outputs": [],
      "source": [
        "# Robust auto-detect helpers for time, vertical force, and cycles.\n",
        "# Works with df columns like \"time_s\", \"Fz (N)\", \"vGRF\", etc.\n",
        "# You can also pass overrides to get_data_context(df=..., time=..., Fz=..., events=...)\n",
        "\n",
        "import re\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# ---------- small utilities ----------\n",
        "def _norm(s: str) -> str:\n",
        "    \"\"\"Lowercase and strip non-alphanumerics for fuzzy matching.\"\"\"\n",
        "    return re.sub(r\"[^a-z0-9]+\", \"\", str(s).lower())\n",
        "\n",
        "def _choose_name(candidates, pool):\n",
        "    for c in candidates:\n",
        "        if c in pool:\n",
        "            return c\n",
        "    return None\n",
        "\n",
        "def _first_existing(names):\n",
        "    g = globals()\n",
        "    for n in names:\n",
        "        if n in g:\n",
        "            return n, g[n]\n",
        "    return None, None\n",
        "\n",
        "# ---------- column picking ----------\n",
        "_TIME_KEYS = [\"time\", \"times\", \"time_s\", \"timesec\", \"sec\", \"seconds\", \"t\"]\n",
        "_FZ_KEYS   = [\"fz\", \"f_z\", \"verticalforce\", \"vforce\", \"grfz\", \"grf_z\", \"vgrf\", \"forcez\", \"fznewton\", \"fzn\"]\n",
        "\n",
        "def _pick_cols(df: pd.DataFrame):\n",
        "    cols = list(df.columns)\n",
        "    nm = {c: _norm(c) for c in cols}\n",
        "\n",
        "    # time column by name\n",
        "    time_col = None\n",
        "    for c, nc in nm.items():\n",
        "        if any(k in nc for k in _TIME_KEYS):\n",
        "            time_col = c\n",
        "            break\n",
        "\n",
        "    # fallback time: first numeric column that is mostly increasing\n",
        "    if time_col is None:\n",
        "        for c in cols:\n",
        "            s = pd.to_numeric(df[c], errors=\"coerce\").values\n",
        "            if np.isfinite(s).sum() > 3:\n",
        "                d = np.diff(s[np.isfinite(s)])\n",
        "                if d.size and np.nanmedian(d) > 0:\n",
        "                    time_col = c\n",
        "                    break\n",
        "\n",
        "    # Fz column by name\n",
        "    fz_col = None\n",
        "    for c, nc in nm.items():\n",
        "        if any(k in nc for k in _FZ_KEYS):\n",
        "            fz_col = c\n",
        "            break\n",
        "\n",
        "    # fallback Fz: numeric column with largest range, excluding time\n",
        "    if fz_col is None:\n",
        "        num_cols = [c for c in cols if c != time_col and pd.api.types.is_numeric_dtype(df[c])]\n",
        "        if num_cols:\n",
        "            rng = []\n",
        "            for c in num_cols:\n",
        "                s = pd.to_numeric(df[c], errors=\"coerce\").values\n",
        "                if np.isfinite(s).sum():\n",
        "                    rng.append((c, float(np.nanmax(s) - np.nanmin(s))))\n",
        "            if rng:\n",
        "                fz_col = max(rng, key=lambda x: x[1])[0]\n",
        "\n",
        "    return time_col, fz_col\n",
        "\n",
        "def _find_df_in_globals():\n",
        "    # preferred names\n",
        "    df_name, df = _first_existing([\"df\", \"data\", \"signals\", \"signal_df\"])\n",
        "    if isinstance(df, pd.DataFrame):\n",
        "        return df_name, df\n",
        "    # any DataFrame that looks usable\n",
        "    for name, obj in globals().items():\n",
        "        if isinstance(obj, pd.DataFrame):\n",
        "            tcol, fzcol = _pick_cols(obj)\n",
        "            if tcol and fzcol:\n",
        "                return name, obj\n",
        "    return None, None\n",
        "\n",
        "# ---------- events to cycles ----------\n",
        "def _infer_cycles_from_events(n):\n",
        "    # common arrays\n",
        "    starts_name, starts = _first_existing([\n",
        "        \"foot_strikes\", \"heel_strikes\", \"strikes\", \"ic_idx\", \"IC_idx\",\n",
        "        \"contact_starts\", \"hs_idx\", \"HS_idx\"\n",
        "    ])\n",
        "    ends_name, ends = _first_existing([\n",
        "        \"toe_offs\", \"offs\", \"to_idx\", \"TO_idx\",\n",
        "        \"contact_ends\"\n",
        "    ])\n",
        "\n",
        "    if starts is not None and ends is not None:\n",
        "        s = np.asarray(starts).astype(int)\n",
        "        e = np.asarray(ends).astype(int)\n",
        "        m = min(len(s), len(e))\n",
        "        pairs = [(int(s[i]), int(e[i])) for i in range(m)\n",
        "                 if 0 <= s[i] < n and 0 <= e[i] < n and e[i] > s[i]]\n",
        "        if pairs:\n",
        "            pairs.sort(key=lambda p: p[0])\n",
        "            return pairs, f\"{starts_name} + {ends_name}\"\n",
        "\n",
        "    # stance_windows as list of tuples\n",
        "    sw_name, sw = _first_existing([\"stance_windows\", \"cycles\", \"contact_windows\", \"stance_idx\"])\n",
        "    if sw is not None:\n",
        "        pairs = []\n",
        "        try:\n",
        "            for a, b in sw:\n",
        "                a, b = int(a), int(b)\n",
        "                if 0 <= a < n and 0 <= b < n and b > a:\n",
        "                    pairs.append((a, b))\n",
        "        except Exception:\n",
        "            pairs = []\n",
        "        if pairs:\n",
        "            pairs.sort(key=lambda p: p[0])\n",
        "            return pairs, f\"{sw_name}\"\n",
        "\n",
        "    # dict of events\n",
        "    ev_name, ev = _first_existing([\"events\", \"evt\", \"gait_events\"])\n",
        "    if isinstance(ev, dict):\n",
        "        s = ev.get(\"start_idx\") or ev.get(\"starts\") or ev.get(\"IC\") or ev.get(\"IC_idx\")\n",
        "        e = ev.get(\"end_idx\")   or ev.get(\"ends\")   or ev.get(\"TO\") or ev.get(\"TO_idx\")\n",
        "        if s is not None and e is not None:\n",
        "            s = np.asarray(s).astype(int)\n",
        "            e = np.asarray(e).astype(int)\n",
        "            m = min(len(s), len(e))\n",
        "            pairs = [(int(s[i]), int(e[i])) for i in range(m)\n",
        "                     if 0 <= s[i] < n and 0 <= e[i] < n and e[i] > s[i]]\n",
        "            if pairs:\n",
        "                pairs.sort(key=lambda p: p[0])\n",
        "                return pairs, f\"{ev_name}\"\n",
        "\n",
        "    return None, None\n",
        "\n",
        "# ---------- threshold fallback ----------\n",
        "def _fallback_cycles_from_threshold(Fz, thresh_ratio=0.15, min_len=5):\n",
        "    \"\"\"Contiguous regions where Fz exceeds thresh_ratio of its max.\"\"\"\n",
        "    Fz = np.asarray(Fz)\n",
        "    if Fz.size == 0 or not np.isfinite(Fz).any():\n",
        "        return []\n",
        "    thr = float(np.nanmax(Fz)) * float(thresh_ratio)\n",
        "    on = Fz > thr\n",
        "    pairs = []\n",
        "    i, n = 0, len(on)\n",
        "    while i < n:\n",
        "        if on[i]:\n",
        "            j = i + 1\n",
        "            while j < n and on[j]:\n",
        "                j += 1\n",
        "            if j - i >= min_len:\n",
        "                pairs.append((i, j - 1))\n",
        "            i = j\n",
        "        else:\n",
        "            i += 1\n",
        "    return pairs\n",
        "\n",
        "# ---------- main entry ----------\n",
        "def _infer_df_and_cols():\n",
        "    # try explicit names first\n",
        "    df_name, df = _first_existing([\"df\", \"data\", \"signals\", \"signal_df\"])\n",
        "    if isinstance(df, pd.DataFrame):\n",
        "        tcol, fzcol = _pick_cols(df)\n",
        "        if tcol and fzcol:\n",
        "            return df, tcol, fzcol, df_name\n",
        "\n",
        "    # build from arrays if available\n",
        "    _, t = _first_existing([\"time\", \"t\", \"Time_s\", \"Time\"])\n",
        "    _, fz = _first_existing([\"Fz\", \"FZ\", \"vertical_force\", \"GRFz\", \"grf_z\", \"fz\", \"vGRF\"])\n",
        "    if t is not None and fz is not None:\n",
        "        df = pd.DataFrame({\"time\": np.asarray(t, dtype=float),\n",
        "                           \"Fz\":   np.asarray(fz, dtype=float)})\n",
        "        return df, \"time\", \"Fz\", \"(constructed)\"\n",
        "\n",
        "    # scan any DataFrame in globals\n",
        "    df_name, df = _find_df_in_globals()\n",
        "    if isinstance(df, pd.DataFrame):\n",
        "        tcol, fzcol = _pick_cols(df)\n",
        "        if tcol and fzcol:\n",
        "            return df, tcol, fzcol, df_name\n",
        "\n",
        "    return None, None, None, None\n",
        "\n",
        "def get_data_context(df=None, time=None, Fz=None, events=None):\n",
        "    \"\"\"\n",
        "    Optional overrides:\n",
        "      df: DataFrame with time and vertical force columns\n",
        "      time: 1D array of time\n",
        "      Fz: 1D array of vertical force\n",
        "      events: dict with keys like start_idx, end_idx, IC, TO\n",
        "    \"\"\"\n",
        "    if df is not None and time is None and Fz is None:\n",
        "        # pick columns from provided df\n",
        "        tcol, fzcol = _pick_cols(df)\n",
        "        if tcol is None or fzcol is None:\n",
        "            raise RuntimeError(\"Could not find time and Fz columns in provided df.\")\n",
        "        time_arr = np.asarray(pd.to_numeric(df[tcol], errors=\"coerce\"), dtype=float)\n",
        "        fz_arr   = np.asarray(pd.to_numeric(df[fzcol], errors=\"coerce\"), dtype=float)\n",
        "        df_source = \"(provided)\"\n",
        "        tcol_name, fz_col_name = tcol, fzcol\n",
        "    elif time is not None and Fz is not None:\n",
        "        time_arr = np.asarray(time, dtype=float)\n",
        "        fz_arr   = np.asarray(Fz, dtype=float)\n",
        "        df_source = \"(from arrays)\"\n",
        "        tcol_name, fz_col_name = \"time\", \"Fz\"\n",
        "    else:\n",
        "        df_auto, tcol, fzcol, df_source = _infer_df_and_cols()\n",
        "        if df_auto is None or tcol is None or fzcol is None:\n",
        "            raise RuntimeError(\"Could not locate time and vertical force. Define a DataFrame with time and Fz columns or arrays named time and Fz.\")\n",
        "        time_arr = np.asarray(pd.to_numeric(df_auto[tcol], errors=\"coerce\"), dtype=float)\n",
        "        fz_arr   = np.asarray(pd.to_numeric(df_auto[fzcol], errors=\"coerce\"), dtype=float)\n",
        "        tcol_name, fz_col_name = tcol, fzcol\n",
        "\n",
        "    n = len(fz_arr)\n",
        "    if events is not None and isinstance(events, dict):\n",
        "        globals()[\"events\"] = events  # make available to _infer_cycles_from_events\n",
        "\n",
        "    pairs, src = _infer_cycles_from_events(n)\n",
        "    if not pairs:\n",
        "        pairs = _fallback_cycles_from_threshold(fz_arr)\n",
        "        src = f\"threshold on {fz_col_name}\"\n",
        "\n",
        "    ctx = {\n",
        "        \"df_source\": df_source,\n",
        "        \"time_col\": tcol_name,\n",
        "        \"fz_col\": fz_col_name,\n",
        "        \"cycle_source\": src,\n",
        "        \"time\": time_arr,\n",
        "        \"Fz\": fz_arr,\n",
        "        \"cycles\": pairs\n",
        "    }\n",
        "    if len(pairs) == 0:\n",
        "        print(\"Warning: no cycles were found. Metrics and plots will be empty until events are available.\")\n",
        "    return ctx\n",
        "\n",
        "# Example use:\n",
        "# ctx = get_data_context()                           # auto\n",
        "# ctx = get_data_context(df=my_df)                   # force a df\n",
        "# ctx = get_data_context(time=t, Fz=fz)              # force arrays\n",
        "# ctx = get_data_context(df=my_df, events={\"IC\": ic_idx, \"TO\": to_idx})\n",
        "print(\"Auto-detect helpers loaded.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2e5d0c72"
      },
      "outputs": [],
      "source": [
        "# Per-cycle metrics with safe context handling.\n",
        "# Computes:\n",
        "#   - peak vertical force\n",
        "#   - contact time\n",
        "#   - loading rate = (peak - start) / (t_peak - t_start)\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "\n",
        "def compute_metrics(time, Fz, cycles):\n",
        "    time = np.asarray(time, dtype=float)\n",
        "    Fz   = np.asarray(Fz, dtype=float)\n",
        "\n",
        "    if time.shape[0] != Fz.shape[0]:\n",
        "        raise ValueError(f\"time and Fz lengths differ: {len(time)} vs {len(Fz)}\")\n",
        "    n = len(Fz)\n",
        "\n",
        "    rows = []\n",
        "    for k, pair in enumerate(cycles, start=1):\n",
        "        if pair is None or len(pair) != 2:\n",
        "            continue\n",
        "        i0, i1 = int(pair[0]), int(pair[1])\n",
        "\n",
        "        # keep only valid, forward windows\n",
        "        if not (0 <= i0 < n and 0 <= i1 < n and i1 > i0):\n",
        "            continue\n",
        "\n",
        "        t0 = float(time[i0]); t1 = float(time[i1])\n",
        "        ct = max(0.0, t1 - t0)\n",
        "\n",
        "        seg  = Fz[i0:i1+1]\n",
        "        tseg = time[i0:i1+1]\n",
        "\n",
        "        # skip empty or all-NaN segments\n",
        "        if seg.size == 0 or not np.isfinite(seg).any():\n",
        "            continue\n",
        "\n",
        "        # peak\n",
        "        imax = int(np.nanargmax(seg))\n",
        "        f0   = float(seg[0])\n",
        "        fpk  = float(seg[imax])\n",
        "        tpk  = float(tseg[imax])\n",
        "\n",
        "        # loading rate\n",
        "        denom = max(1e-9, tpk - t0)\n",
        "        lr = (fpk - f0) / denom\n",
        "\n",
        "        rows.append({\n",
        "            \"cycle\": k,\n",
        "            \"start_idx\": i0,\n",
        "            \"end_idx\": i1,\n",
        "            \"start_time_s\": t0,\n",
        "            \"end_time_s\": t1,\n",
        "            \"contact_time_s\": ct,\n",
        "            \"peak_vforce_N\": fpk,\n",
        "            \"peak_time_s\": tpk,\n",
        "            \"loading_rate_N_per_s\": lr\n",
        "        })\n",
        "\n",
        "    return pd.DataFrame(rows, columns=[\n",
        "        \"cycle\",\"start_idx\",\"end_idx\",\"start_time_s\",\"end_time_s\",\n",
        "        \"contact_time_s\",\"peak_vforce_N\",\"peak_time_s\",\"loading_rate_N_per_s\"\n",
        "    ])\n",
        "\n",
        "# Get context safely:\n",
        "try:\n",
        "    ctx  # noqa: F821\n",
        "except NameError:\n",
        "    try:\n",
        "        # If your earlier cell defined get_data_context(), use it\n",
        "        ctx = get_data_context()\n",
        "    except NameError as e:\n",
        "        raise RuntimeError(\n",
        "            \"No ctx found. Either run the cell that defines get_data_context() \"\n",
        "            \"or call compute_metrics(time, Fz, cycles) with your own arrays.\"\n",
        "        ) from e\n",
        "\n",
        "# Compute and save\n",
        "metrics_df = compute_metrics(ctx[\"time\"], ctx[\"Fz\"], ctx[\"cycles\"])\n",
        "print(f\"Computed {len(metrics_df)} cycles\")\n",
        "\n",
        "OUTPUT_DIR = Path(\"report_outputs\")\n",
        "OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "csv_path = OUTPUT_DIR / \"metrics.csv\"\n",
        "metrics_df.to_csv(csv_path, index=False)\n",
        "print(\"Saved:\", csv_path.resolve())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ab82eb04"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Create the three figures:\n",
        "# 1) Time plot with stance shading\n",
        "# 2) Cycle overlay\n",
        "# 3) Per-cycle peaks\n",
        "\n",
        "time = ctx[\"time\"]\n",
        "Fz   = ctx[\"Fz\"]\n",
        "cycles = ctx[\"cycles\"]\n",
        "\n",
        "# 1) Time plot with stance shading\n",
        "plt.figure()\n",
        "plt.plot(time, Fz, linewidth=1.5)\n",
        "for (i0, i1) in cycles:\n",
        "    t0, t1 = time[i0], time[i1]\n",
        "    plt.fill_between([t0, t1], [max(Fz.min(), 0)], [max(Fz)], alpha=0.15)\n",
        "plt.xlabel(\"Time [s]\")\n",
        "plt.ylabel(\"Vertical Force [N]\")\n",
        "plt.title(\"Vertical Force over Time with Stance Shading\")\n",
        "fig1_path = OUTPUT_DIR / \"fig_time.png\"\n",
        "plt.savefig(fig1_path, dpi=150, bbox_inches=\"tight\")\n",
        "plt.close()\n",
        "print(\"Saved:\", fig1_path.resolve())\n",
        "\n",
        "# 2) Cycle overlay: align each cycle to its own t=0 and plot Fz\n",
        "plt.figure()\n",
        "for (i0, i1) in cycles:\n",
        "    tseg = time[i0:i1+1]\n",
        "    fseg = Fz[i0:i1+1]\n",
        "    if len(tseg) < 2:\n",
        "        continue\n",
        "    tnorm = tseg - tseg[0]\n",
        "    plt.plot(tnorm, fseg, linewidth=1.0, alpha=0.9)\n",
        "plt.xlabel(\"Time from contact start [s]\")\n",
        "plt.ylabel(\"Vertical Force [N]\")\n",
        "plt.title(\"Cycle Overlay - Vertical Force\")\n",
        "fig2_path = OUTPUT_DIR / \"fig_overlay.png\"\n",
        "plt.savefig(fig2_path, dpi=150, bbox_inches=\"tight\")\n",
        "plt.close()\n",
        "print(\"Saved:\", fig2_path.resolve())\n",
        "\n",
        "# 3) Per-cycle peaks: bar chart of peak vertical force\n",
        "plt.figure()\n",
        "if len(cycles) > 0 and len(metrics_df):\n",
        "    peaks = metrics_df[\"peak_vforce_N\"].values\n",
        "    x = np.arange(1, len(peaks) + 1)\n",
        "    plt.bar(x, peaks)\n",
        "    plt.xlabel(\"Cycle\")\n",
        "    plt.ylabel(\"Peak Vertical Force [N]\")\n",
        "    plt.title(\"Per-cycle Peak Vertical Force\")\n",
        "else:\n",
        "    plt.text(0.5, 0.5, \"No cycles available\", ha=\"center\", va=\"center\")\n",
        "fig3_path = OUTPUT_DIR / \"fig_peaks.png\"\n",
        "plt.savefig(fig3_path, dpi=150, bbox_inches=\"tight\")\n",
        "plt.close()\n",
        "print(\"Saved:\", fig3_path.resolve())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "34b7274c"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Write simple report.html that links to metrics.csv and embeds the figures using string.Template\n",
        "from datetime import datetime\n",
        "from string import Template\n",
        "\n",
        "fig1_rel = \"fig_time.png\"\n",
        "fig2_rel = \"fig_overlay.png\"\n",
        "fig3_rel = \"fig_peaks.png\"\n",
        "\n",
        "tpl = Template(\n",
        "    \"<!DOCTYPE html>\\n\"\n",
        "    \"<html lang=\\\"en\\\">\\n\"\n",
        "    \"<head>\\n\"\n",
        "    \"  <meta charset=\\\"utf-8\\\">\\n\"\n",
        "    \"  <meta name=\\\"viewport\\\" content=\\\"width=device-width, initial-scale=1\\\">\\n\"\n",
        "    \"  <title>Chapter 5 Report - PoseIQ</title>\\n\"\n",
        "    \"  <style>\\n\"\n",
        "    \"    body { font-family: system-ui, -apple-system, Segoe UI, Roboto, Arial, sans-serif; line-height: 1.5; margin: 24px; }\\n\"\n",
        "    \"    header { margin-bottom: 16px; }\\n\"\n",
        "    \"    h1, h2, h3 { margin: 0.4em 0; }\\n\"\n",
        "    \"    .meta { color: #444; font-size: 0.95rem; }\\n\"\n",
        "    \"    .card { border: 1px solid #ddd; border-radius: 12px; padding: 16px; margin: 16px 0; }\\n\"\n",
        "    \"    img { max-width: 100%; height: auto; display: block; margin: 12px 0; }\\n\"\n",
        "    \"    a.button { display: inline-block; padding: 8px 12px; border: 1px solid #333; border-radius: 8px; text-decoration: none; color: #111; }\\n\"\n",
        "    \"  </style>\\n\"\n",
        "    \"</head>\\n\"\n",
        "    \"<body>\\n\"\n",
        "    \"  <header>\\n\"\n",
        "    \"    <h1>Export and Report</h1>\\n\"\n",
        "    \"    <div class=\\\"meta\\\">Generated $stamp</div>\\n\"\n",
        "    \"    <div class=\\\"meta\\\">Source columns: time = $time_col, vertical force = $fz_col from $df_source</div>\\n\"\n",
        "    \"    <div class=\\\"meta\\\">Cycles: $cycle_count via $cycle_source</div>\\n\"\n",
        "    \"  </header>\\n\"\n",
        "    \"\\n\"\n",
        "    \"  <section class=\\\"card\\\">\\n\"\n",
        "    \"    <h2>Metrics</h2>\\n\"\n",
        "    \"    <p>Download the CSV with per-cycle metrics.</p>\\n\"\n",
        "    \"    <p><a class=\\\"button\\\" href=\\\"metrics.csv\\\" download>metrics.csv</a></p>\\n\"\n",
        "    \"  </section>\\n\"\n",
        "    \"\\n\"\n",
        "    \"  <section class=\\\"card\\\">\\n\"\n",
        "    \"    <h2>Figures</h2>\\n\"\n",
        "    \"    <h3>Time plot with stance shading</h3>\\n\"\n",
        "    \"    <img src=\\\"$fig1\\\" alt=\\\"Vertical Force over Time with Stance Shading\\\">\\n\"\n",
        "    \"    <h3>Cycle overlay</h3>\\n\"\n",
        "    \"    <img src=\\\"$fig2\\\" alt=\\\"Cycle Overlay - Vertical Force\\\">\\n\"\n",
        "    \"    <h3>Per-cycle peak vertical force</h3>\\n\"\n",
        "    \"    <img src=\\\"$fig3\\\" alt=\\\"Per-cycle peak vertical force\\\">\\n\"\n",
        "    \"  </section>\\n\"\n",
        "    \"\\n\"\n",
        "    \"  <footer class=\\\"card\\\">\\n\"\n",
        "    \"    <div><strong>Ebook:</strong> A Hands-On Guide to Biomechanics Data Analysis with Python and AI</div>\\n\"\n",
        "    \"    <div><strong>Author:</strong> Dr. Hossein Mokhtarzadeh</div>\\n\"\n",
        "    \"    <div><strong>Powered by:</strong> PoseIQ™</div>\\n\"\n",
        "    \"  </footer>\\n\"\n",
        "    \"</body>\\n\"\n",
        "    \"</html>\\n\"\n",
        ")\n",
        "\n",
        "html = tpl.safe_substitute(\n",
        "    stamp=datetime.now().isoformat(timespec=\"seconds\"),\n",
        "    time_col=ctx[\"time_col\"],\n",
        "    fz_col=ctx[\"fz_col\"],\n",
        "    df_source=ctx[\"df_source\"],\n",
        "    cycle_count=len(ctx[\"cycles\"]),\n",
        "    cycle_source=ctx[\"cycle_source\"],\n",
        "    fig1=fig1_rel,\n",
        "    fig2=fig2_rel,\n",
        "    fig3=fig3_rel,\n",
        ")\n",
        "\n",
        "html_path = OUTPUT_DIR / \"report.html\"\n",
        "with open(html_path, \"w\", encoding=\"utf-8\") as f:\n",
        "    f.write(html)\n",
        "\n",
        "print(\"Saved:\", html_path.resolve())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "45fd8dee"
      },
      "source": [
        "You are done. The `report_outputs` folder now holds `metrics.csv` and `report.html` along with three figures. If cycles are empty, confirm earlier chapters produced stance events or adjust the threshold in the fallback code cell.\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}